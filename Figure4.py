"""

"""

import warnings 
import numpy as np 
import pandas as pd 
import seaborn as sns 
import matplotlib.pyplot as plt 

from scipy.stats import linregress
from sklearn.metrics.pairwise import cosine_similarity


MessageEmbeddings = pd.read_pickle('./Database/MessageEmbeddings.pkl')
"""print(MessageEmbeddings.columns)
Index(['UserId', 'Experiment', 'EmailId', 'PhaseTrial', 'Decision',
       'MessageNum', 'Message', 'EmailType', 'PhaseValue',
       'ExperimentCondition', 'Confidence', 'EmailAction', 'ReactionTime',
       'Correct', 'Role', 'Content', 'MessageEmbedding'],
      dtype='object')
"""
MessageEmbeddings.rename(columns={'Embedding':'MessageEmbedding'}, inplace=True)
MessageEmbeddings["MessageEmbedding"] = [np.array([float(y) for y in x]).reshape(1,-1) for x in MessageEmbeddings["MessageEmbedding"]]

Annotations =  pd.read_pickle('./Database/Annotations.pkl')
"""
Index(['UserId', 'Experiment', 'ExperimentCondition', 'EmailId', 'PhaseTrial',
       'Decision', 'EmailType', 'PhaseValue', 'Confidence', 'EmailAction',
       'ReactionTime', 'Correct'],
      dtype='object')
"""

Demographics = pd.read_pickle('./Database/Demographics.pkl')
"""
Index(['UserId', 'Age', 'Gender', 'Education', 'Country', 'Victim', 'Chatbot',
       'Q0', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'PQ1', 'PQ2', 'PQ3', 'PQ4', 'PQ5'],
      dtype='object')
"""

DemographicsEmbeddings = pd.read_pickle('./Database/DemographicsEmbeddings.pkl')
"""
Index(['UserId', 'Age', 'Gender', 'Education', 'Country', 'Victim', 'Chatbot',
       'Q0', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'PQ1', 'PQ2', 'PQ3', 'PQ4', 'PQ5',
       'Open Response Embedding'],
      dtype='object')
"""
DemographicsEmbeddings = DemographicsEmbeddings[DemographicsEmbeddings['Open Response Embedding'] != -1]
DemographicsEmbeddings.rename(columns={'Open Response Embedding': 'DemographicsEmbedding'}, inplace=True)
DemographicsEmbeddingList = []
for idx, DemographicsEmbedding in DemographicsEmbeddings.iterrows():
    DemographicsEmbeddingArray = np.array([float(y) for y in DemographicsEmbedding['DemographicsEmbedding']]).reshape(1,-1)
    if(DemographicsEmbeddingArray.shape != (1,3072)):
        print(DemographicsEmbeddingArray.shape)
        assert(False)
    DemographicsEmbeddingList.append(DemographicsEmbeddingArray)

DemographicsEmbeddings["DemographicsEmbedding"] = DemographicsEmbeddingList

EmailEmbeddings = pd.read_pickle("./Database/EmailEmbeddings.pkl")
"""print(EmailEmbeddings.columns)
Index(['EmailId', 'BaseEmailID', 'Author', 'Style', 'Embedding',
       'Phishing Similarity', 'Ham Similarity'],
      dtype='object')
"""
EmailEmbeddings.rename(columns={'Embedding':'EmailEmbedding'}, inplace=True)
EmailEmbeddings["EmailEmbedding"] = [np.array([float(y) for y in x]).reshape(1,-1) for x in EmailEmbeddings["EmailEmbedding"]]

Improvements = []

MessageEmbeddings['User Improvement'] = [Annotations[(Annotations['UserId'] == MessageEmbedding['UserId']) & (Annotations['PhaseValue'] == 'postTraining')]['Correct'].mean() - Annotations[(Annotations['UserId'] == MessageEmbedding['UserId']) & (Annotations['PhaseValue'] == 'preTraining')]['Correct'].mean() for _, MessageEmbedding in MessageEmbeddings.iterrows()]

"""
Post-Experiment Questionnaire

Q1. Of the phishing emails you’ve encountered, what percentage do you think were generated by artificial intelligence models?
	•	☐ 100% of the phishing emails I read were written by an Artificial Intelligence model.
	•	☐ 75% of the phishing emails I read were written by an Artificial Intelligence model.
	•	☐ 50% of the phishing emails I read were written by an Artificial Intelligence model.
	•	☐ 25% of the phishing emails I read were written by an Artificial Intelligence model.

Q2. Of the ham (i.e., non-phishing) emails you’ve encountered, what percentage do you think were generated by artificial intelligence models?
	•	☐ 100% of the ham emails I read were written by an Artificial Intelligence model.
	•	☐ 75% of the ham emails I read were written by an Artificial Intelligence model.
	•	☐ 50% of the ham emails I read were written by an Artificial Intelligence model.
	•	☐ 25% of the ham emails I read were written by an Artificial Intelligence model.

Q3. Of the phishing emails you’ve encountered, what percentage do you think were styled (i.e., the appearance and format) by artificial intelligence models?
	•	☐ 100% of the phishing emails I read were styled by an Artificial Intelligence model.
	•	☐ 75% of the phishing emails I read were styled by an Artificial Intelligence model.
	•	☐ 50% of the phishing emails I read were styled by an Artificial Intelligence model.
	•	☐ 25% of the phishing emails I read were styled by an Artificial Intelligence model.

Q4. Of the ham (i.e., non-phishing) emails you’ve encountered, what percentage do you think were styled (i.e., the appearance and format) by artificial intelligence models?
	•	☐ 100% of the ham emails I read were styled by an Artificial Intelligence model.
	•	☐ 75% of the ham emails I read were styled by an Artificial Intelligence model.
	•	☐ 50% of the ham emails I read were styled by an Artificial Intelligence model.
	•	☐ 25% of the ham emails I read were styled by an Artificial Intelligence model.

Q5. What criteria did you use to identify whether an email was a phishing attempt?
	•	Open response: _______________________________________________
"""

WritingPerceptions = []
QuizScores = []
ResponseMessageSimilarities = []
for idx, MessageEmbedding in MessageEmbeddings.iterrows():
    
    UserDemographics = DemographicsEmbeddings[DemographicsEmbeddings['UserId'] == MessageEmbedding['UserId']]
    if(len(UserDemographics) == 0):
        WritingPerceptions.append(-1)
        QuizScores.append(-1)
        ResponseMessageSimilarities.append(-1)
        continue 

    PQ1 = UserDemographics['PQ1'].item()
    PQ2 = UserDemographics['PQ2'].item()
    PQ3 = UserDemographics['PQ3'].item()
    PQ4 = UserDemographics['PQ4'].item()
    WritingPerception = 0 
    

    for PQ in [PQ1, PQ2, PQ3, PQ4]:
        if('0p' in PQ):
                WritingPerception += 0
        if('25p' in PQ):
                WritingPerception += 25
        if('50p' in PQ):
                WritingPerception += 50 
        if('75p' in PQ):
                WritingPerception += 75
        if('100p' in PQ):
                WritingPerception += 100
    
    Q1 = UserDemographics['Q1'].item()
    Q2 = UserDemographics['Q2'].item()
    Q3 = UserDemographics['Q3'].item()
    Q4 = UserDemographics['Q4'].item()
    Q5 = UserDemographics['Q5'].item()

    QuizScore = 0 
    if(Q1 == 0):
        QuizScore += 1
    if(Q2 == 1):
        QuizScore += 1 
    if(Q3 == 3):
        QuizScore += 1 
    if(Q4 == 2):
        QuizScore += 1
    if(Q5 == 1):
        QuizScore += 1

    m = MessageEmbedding['MessageEmbedding']
    e = UserDemographics['DemographicsEmbedding'].item()
    if(len(e[0]) == 0 or len(m[0]) == 0):
        ResponseMessageSimilarity = -1
    else:
        ResponseMessageSimilarity = float(round(float(cosine_similarity(m, e)[0, 0]) / 0.025) * 0.025)

    WritingPerception = WritingPerception / 4
    
    WritingPerceptions.append(WritingPerception)
    QuizScores.append(QuizScore)
    ResponseMessageSimilarities.append(ResponseMessageSimilarity)

MessageEmbeddings['Perception of Emails as AI Generated'] = WritingPerceptions
MessageEmbeddings['Pre-Experiment Quiz Score'] = QuizScores
MessageEmbeddings['Response Message Similarity'] = ResponseMessageSimilarities
MessageEmbeddings = MessageEmbeddings[MessageEmbeddings['Response Message Similarity'] != -1]

# ── Join message → email embeddings ───────────────────────────────────────────
df = MessageEmbeddings.merge(
    EmailEmbeddings[["EmailId", "EmailEmbedding"]],
    on="EmailId",
    how="left",
    suffixes=("", "_Email"),
)

df = df.merge(
    DemographicsEmbeddings,
    on="UserId",
    how="left"
)

# 
"""
Index(['UserId', 'Experiment', 'EmailId', 'PhaseTrial', 'Decision',
       'MessageNum', 'Message', 'EmailType', 'PhaseValue',
       'ExperimentCondition', 'Confidence', 'EmailAction', 'ReactionTime',
       'Correct', 'Role', 'Content', 'MessageEmbedding', 'User Improvement',
       'AI Writing Perception', 'AI Code Generation Perception',
       'EmailEmbedding'],
      dtype='object')
"""

# Keep only valid, same-dimension pairs
df = df.dropna(subset=["MessageEmbedding", "EmailEmbedding"]).copy()
same_dim = df.apply(lambda r: r["MessageEmbedding"].shape[1] == r["EmailEmbedding"].shape[1], axis=1)
df = df[same_dim].copy()

# Compute scalar cosine similarity
df["Message Cosine Similarity to Email"] = [
    float(round(float(cosine_similarity(m, e)[0, 0]) / 0.025) * 0.025) for m, e in zip(df["MessageEmbedding"], df["EmailEmbedding"])
]

df['Message Cosine Similarity to Email'] = df.groupby('Role')['Message Cosine Similarity to Email'].transform(
    lambda s: (s - s.min()) / (s.max() - s.min()) if s.max() > s.min() else 0.0
)
# Normalize to between 0 and 1 


# ── Plots: similarity vs outcomes, split by role ─────────────────────
targets = ['Age', 'Gender', 'Education', 'Victim', 'Chatbot', 'ExperimentCondition']
# 1) Binary / ordinal
df['Gender Number'] = df['Gender'].map({'M': 0, 'F': 1}).astype('float')

# Use an *ordered* scale for education (years is nicer than 0..3)
edu_map = {'HS': 12, 'BD': 16, 'MD': 18, 'PD': 21}
df['Education Years'] = df['Education'].map(edu_map).astype('float')

exp_map = {np.nan: 0, 'A': 1, 'YM': 2, 'YF': 3}
df['Phishing Experience'] = df['Victim'].map(exp_map).astype('float')

exp_map = {np.nan: 0, 'A': 1, 'YM': 2, 'YF': 3}
df['Chatbot Experience'] = df['Chatbot'].map(exp_map).astype('float')

exp_map = {'IBL Emails Written Feedback':2, 'IBL Emails Points Feedback':1, 'Random Emails Written Feedback':1, 'Ablation Experiment':0}
df['Cognitive Model Activity'] = df['ExperimentCondition'].map(exp_map).astype('float')

# 3) Build numeric targets to plot
targets = ['Age', 'Gender Number', 'Education Years', 'Phishing Experience', 'Chatbot Experience', 'Cognitive Model Activity']

# Now your plotting loop can iterate over `targets`

role_col = 'Role'

# Plot regression using binned means
fig, axes = plt.subplots(2, 3, figsize=(18, 10), constrained_layout=True)
for ax_idx, (ax, target) in enumerate(zip(axes.flat, targets)):
    sub = df[["Message Cosine Similarity to Email", role_col, target]].copy()
    # ensure numeric y
    sub[target] = pd.to_numeric(sub[target], errors="coerce")
    
    sub = sub[sub[target].notna() & sub["Message Cosine Similarity to Email"].notna()]
    sub["_role"] = sub[role_col].astype(str).str.lower()


    # Bin similarity by 0.01 (round to 2 decimals) and aggregate per bin+role
    sub["SimBin"] = sub["Message Cosine Similarity to Email"].round(2)
    agg = (
        sub.groupby(["_role", "SimBin"], as_index=False)
        .agg(
            x=("Message Cosine Similarity to Email", "mean"),  # bin mean of similarity
            y=(target, "mean"),                                  # bin mean of target
            n=("Message Cosine Similarity to Email", "size"),   # bin count (for reference)
        )
    )

    ax.set_xlim([0,1])

    for role_name in ["user", "system"]:
        ss = agg[agg["_role"] == role_name]
        role_label = "Human Student" if role_name == "user" else "Teacher LLM"
        if ss.empty:
            continue
        sns.regplot(
            data=ss,
            x="x",
            y="y",
            ax=ax,
            scatter=True,
            ci=95,
            scatter_kws={"alpha": 0.5, "s": 30},
            label=role_label,
            truncate=False
        )
        # --- Add regression stats as text ---
        # Only compute stats if there are at least two unique x points
        if len(ss) >= 2 and ss["x"].nunique() >= 2:
            res = linregress(ss["x"], ss["y"])  # slope, intercept, rvalue, pvalue, etc.
            r2 = res.rvalue ** 2
            pval = res.pvalue

            # Stack annotations near the top of each axes; one line per role
            y_text = 0.98 if role_name == "user" else 0.90
            ax.text(
                0.02,
                y_text,
                f"{role_label}: $R^2$={r2:.3f}, p={pval:.3g}",
                transform=ax.transAxes,
                fontsize=14,
                va="top",
            )

    if(ax_idx == 0 ):
        ax.legend(title="Message Sender", loc='lower left', title_fontsize=16, fontsize=14)
    else: 
        legend = ax.legend()
        legend.remove()

    ax.set_title(f"{target}\nvs Message↔Email Cosine Similarity", fontsize=16)
    ax.set_xlabel("Message Cosine Similarity to Email", fontsize=14)
    ax.set_ylabel(target, fontsize=14)

plt.show()
